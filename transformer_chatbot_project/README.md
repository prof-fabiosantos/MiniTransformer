# Chatbot com Mini Transformer

Este projeto implementa um chatbot leve baseado na arquitetura Transformer, treinado com pares de pergunta e resposta, usando PyTorch e Streamlit.

---

## ğŸš€ Funcionalidades

* Treinamento com dados estilo FAQ
* GeraÃ§Ã£o de respostas com controle por:

  * `temperature`
  * `top-k`
  * `top-p` (nucleus sampling)
* Interface interativa com Streamlit

---

## ğŸ“¦ Requisitos

```bash
pip install torch streamlit numpy
```

---

## ğŸ§  Treinamento do modelo

1. Crie um arquivo `textDataset.txt` com perguntas e respostas, uma por linha:

```
pergunta: qual a capital do brasil? resposta: brasÃ­lia.
pergunta: quanto Ã© 2 mais 2? resposta: 4.
```

2. Execute o script de treinamento:

```bash
python train_transformer_v3.py
```

Isso irÃ¡ gerar os arquivos:

* `modelo_transformer.pt`
* `vocab_transformer.json`

---

## ğŸ’¬ Usando o Chatbot (Streamlit)

Execute o app com:

```bash
streamlit run transformer_chabot_v2.py
```

### Interface permite ajustar:

* Quantidade de palavras geradas
* Temperatura da amostragem
* Top-k e Top-p

Digite uma pergunta como:

```
qual a capital do brasil?
```

E veja a resposta gerada com base no modelo treinado.

---

## ğŸ“ Estrutura do projeto

```
â”œâ”€â”€ transformer_chatbot_treino.py      # Script de treino
â”œâ”€â”€ transformer_chatbot_app.py         # Interface web com Streamlit
â”œâ”€â”€ model.py                           # Arquitetura Transformer
â”œâ”€â”€ textDataset.txt                    # Dataset de treino
â”œâ”€â”€ modelo_transformer.pt              # Modelo salvo
â”œâ”€â”€ vocab_transformer.json             # VocabulÃ¡rio salvo
```

---

## ğŸ“Œ ObservaÃ§Ãµes

* O modelo foi feito para fins didÃ¡ticos.
* Pode ser expandido com embeddings melhores e tokenizer de subpalavras.

---

## ğŸ§‘â€ğŸ’» Autor

Este projeto foi gerado com o apoio do ChatGPT e adaptaÃ§Ãµes personalizadas para mini Transformers.
